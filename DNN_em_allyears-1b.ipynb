{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for h->aa->bbtautau signal/background separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dense, Dropout\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import kerastuner\n",
    "from kerastuner import Hyperband\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load root files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_obs18 = ROOT.RDataFrame('emu_tree', 'root_raw/em18_raw/data_obs.root')\n",
    "file_sig18 = ROOT.RDataFrame('emu_tree', {'root_raw/em18_raw/ggH_bbtt*.root', 'root_raw/em18_raw/vbf_bbtt*.root'})\n",
    "file_ZTT18 = ROOT.RDataFrame('emu_tree', 'root_raw/em18_raw/embedded.root')\n",
    "file_TT18 = ROOT.RDataFrame('emu_tree', 'root_raw/em18_raw/TT*.root')\n",
    "\n",
    "file_obs17 = ROOT.RDataFrame('emu_tree', 'root_raw/em17_raw/data_obs.root')\n",
    "file_sig17 = ROOT.RDataFrame('emu_tree',  {'root_raw/em17_raw/ggH_bbtt*.root', 'root_raw/em17_raw/vbf_bbtt*.root'})\n",
    "file_ZTT17 = ROOT.RDataFrame('emu_tree', 'root_raw/em17_raw/embedded.root')\n",
    "file_TT17 = ROOT.RDataFrame('emu_tree', 'root_raw/em17_raw/TT*.root')\n",
    "\n",
    "file_obs16 = ROOT.RDataFrame('emu_tree', 'root_raw/em16_raw/data_obs.root')\n",
    "file_sig16 = ROOT.RDataFrame('emu_tree', {'root_raw/em16_raw/ggH_bbtt*.root', 'root_raw/em16_raw/vbf_bbtt*.root'})\n",
    "file_ZTT16 = ROOT.RDataFrame('emu_tree', 'root_raw/em16_raw/embedded.root')\n",
    "file_TT16 = ROOT.RDataFrame('emu_tree', 'root_raw/em16_raw/TT*.root')\n",
    "\n",
    "files18 = [file_obs18, file_sig18, file_ZTT18, file_TT18]\n",
    "files17 = [file_obs17, file_sig17, file_ZTT17, file_TT17]\n",
    "files16 = [file_obs16, file_sig16, file_ZTT16, file_TT16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b events\n",
    "for i in range(len(files18)):\n",
    "    files18[i] = files18[i].Filter('bpt_deepcsv_1>20 && bscore_deepcsv_1>0.4184 && bpt_deepcsv_2<0')\n",
    "    files17[i] = files17[i].Filter('bpt_deepcsv_1>20 && bscore_deepcsv_1>0.4941 && bpt_deepcsv_2<0')\n",
    "    files16[i] = files16[i].Filter('bpt_deepcsv_1>20 && bscore_deepcsv_1>0.6321 && bpt_deepcsv_2<0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 4-vectors, invariant masses and etc.\n",
    "myele = 'ROOT::Math::PtEtaPhiMVector(pt_1,eta_1,phi_1,m_1)'\n",
    "mymu = 'ROOT::Math::PtEtaPhiMVector(pt_2,eta_2,phi_2,m_2)'\n",
    "mymet = 'ROOT::Math::PtEtaPhiMVector(met,0,metphi,0)'\n",
    "mytt = 'ROOT::Math::PtEtaPhiMVector((myele+mymu+mymet).Pt(),(myele+mymu+mymet).Eta(),(myele+mymu+mymet).Phi(),m_sv)'\n",
    "myb1 = 'ROOT::Math::PtEtaPhiMVector(bpt_deepcsv_1,beta_deepcsv_1,bphi_deepcsv_1,bm_deepcsv_1)'\n",
    "m_btt = '(mytt+myb1).M()'\n",
    "m_b1ele = '(myele+myb1).M()'\n",
    "m_b1mu = '(mymu+myb1).M()'\n",
    "dR_tt = 'ROOT::Math::VectorUtil::DeltaR(myele,mymu)'\n",
    "dR_b1ele = 'ROOT::Math::VectorUtil::DeltaR(myele,myb1)'\n",
    "dR_b1mu = 'ROOT::Math::VectorUtil::DeltaR(mymu,myb1)'\n",
    "dR_b1tt = 'ROOT::Math::VectorUtil::DeltaR(myb1,mytt)'\n",
    "tt_pt = 'mytt.Pt()'\n",
    "tt_eta = 'mytt.Eta()'\n",
    "\n",
    "# define transverse masses mT and D_zeta\n",
    "mT_ele = 'sqrt(pow(myele.Pt()+mymet.Pt(),2)-pow(myele.Px()+mymet.Px(),2)-pow(myele.Py()+mymet.Py(),2))'\n",
    "mT_mu = 'sqrt(pow(mymu.Pt()+mymet.Pt(),2)-pow(mymu.Px()+mymet.Px(),2)-pow(mymu.Py()+mymet.Py(),2))'\n",
    "mT_b1 = 'sqrt(pow(myb1.Pt()+mymet.Pt(),2)-pow(myb1.Px()+mymet.Px(),2)-pow(myb1.Py()+mymet.Py(),2))'\n",
    "norm_zeta = 'sqrt(pow(myele.Px()/myele.Pt()+mymu.Px()/mymu.Pt(),2)+pow(myele.Py()/myele.Pt()+mymu.Py()/mymu.Pt(),2))'\n",
    "x_zeta = '(myele.Px()/myele.Pt()+mymu.Px()/mymu.Pt())/norm_zeta'\n",
    "y_zeta = '(myele.Py()/myele.Pt()+mymu.Py()/mymu.Pt())/norm_zeta'\n",
    "p_zeta_mis = 'mymet.Px()*x_zeta+mymet.Py()*y_zeta'\n",
    "pzeta_vis = '(myele.Px()+mymu.Px())*x_zeta+(myele.Py()+mymu.Py())*y_zeta'\n",
    "Dzeta = 'p_zeta_mis-0.85*pzeta_vis'\n",
    "\n",
    "# add defined variables to dataframe\n",
    "for i in range(len(files18)):\n",
    "    files18[i] = files18[i].Define('myele', myele)\\\n",
    "    .Define('mymu', mymu)\\\n",
    "    .Define('mymet', mymet)\\\n",
    "    .Define('mytt', mytt)\\\n",
    "    .Define('myb1', myb1)\\\n",
    "    .Define('m_btt', m_btt)\\\n",
    "    .Define('m_b1ele', m_b1ele)\\\n",
    "    .Define('m_b1mu', m_b1mu)\\\n",
    "    .Define('dR_tt', dR_tt)\\\n",
    "    .Define('dR_b1ele', dR_b1ele)\\\n",
    "    .Define('dR_b1mu', dR_b1mu)\\\n",
    "    .Define('dR_b1tt', dR_b1tt)\\\n",
    "    .Define('tt_pt', tt_pt)\\\n",
    "    .Define('tt_eta', tt_eta)\\\n",
    "    .Define('mT_ele', mT_ele)\\\n",
    "    .Define('mT_mu', mT_mu)\\\n",
    "    .Define('mT_b1', mT_b1)\\\n",
    "    .Define('norm_zeta', norm_zeta)\\\n",
    "    .Define('x_zeta', x_zeta)\\\n",
    "    .Define('y_zeta', y_zeta)\\\n",
    "    .Define('p_zeta_mis', p_zeta_mis)\\\n",
    "    .Define('pzeta_vis', pzeta_vis)\\\n",
    "    .Define('Dzeta', Dzeta)\n",
    "    \n",
    "    files17[i] = files17[i].Define('myele', myele)\\\n",
    "    .Define('mymu', mymu)\\\n",
    "    .Define('mymet', mymet)\\\n",
    "    .Define('mytt', mytt)\\\n",
    "    .Define('myb1', myb1)\\\n",
    "    .Define('m_btt', m_btt)\\\n",
    "    .Define('m_b1ele', m_b1ele)\\\n",
    "    .Define('m_b1mu', m_b1mu)\\\n",
    "    .Define('dR_tt', dR_tt)\\\n",
    "    .Define('dR_b1ele', dR_b1ele)\\\n",
    "    .Define('dR_b1mu', dR_b1mu)\\\n",
    "    .Define('dR_b1tt', dR_b1tt)\\\n",
    "    .Define('tt_pt', tt_pt)\\\n",
    "    .Define('tt_eta', tt_eta)\\\n",
    "    .Define('mT_ele', mT_ele)\\\n",
    "    .Define('mT_mu', mT_mu)\\\n",
    "    .Define('mT_b1', mT_b1)\\\n",
    "    .Define('norm_zeta', norm_zeta)\\\n",
    "    .Define('x_zeta', x_zeta)\\\n",
    "    .Define('y_zeta', y_zeta)\\\n",
    "    .Define('p_zeta_mis', p_zeta_mis)\\\n",
    "    .Define('pzeta_vis', pzeta_vis)\\\n",
    "    .Define('Dzeta', Dzeta)\n",
    "    \n",
    "    files16[i] = files16[i].Define('myele', myele)\\\n",
    "    .Define('mymu', mymu)\\\n",
    "    .Define('mymet', mymet)\\\n",
    "    .Define('mytt', mytt)\\\n",
    "    .Define('myb1', myb1)\\\n",
    "    .Define('m_btt', m_btt)\\\n",
    "    .Define('m_b1ele', m_b1ele)\\\n",
    "    .Define('m_b1mu', m_b1mu)\\\n",
    "    .Define('dR_tt', dR_tt)\\\n",
    "    .Define('dR_b1ele', dR_b1ele)\\\n",
    "    .Define('dR_b1mu', dR_b1mu)\\\n",
    "    .Define('dR_b1tt', dR_b1tt)\\\n",
    "    .Define('tt_pt', tt_pt)\\\n",
    "    .Define('tt_eta', tt_eta)\\\n",
    "    .Define('mT_ele', mT_ele)\\\n",
    "    .Define('mT_mu', mT_mu)\\\n",
    "    .Define('mT_b1', mT_b1)\\\n",
    "    .Define('norm_zeta', norm_zeta)\\\n",
    "    .Define('x_zeta', x_zeta)\\\n",
    "    .Define('y_zeta', y_zeta)\\\n",
    "    .Define('p_zeta_mis', p_zeta_mis)\\\n",
    "    .Define('pzeta_vis', pzeta_vis)\\\n",
    "    .Define('Dzeta', Dzeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply baseline selection cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## 2 0 1 8 ##########################\n",
    "# 2018 ele+mu trigger requirements\n",
    "trigger823_18 = '(passMu8E23DZ && matchMu8E23DZ_1 && filterMu8E23DZ_1 && matchMu8E23DZ_2 && filterMu8E23DZ_2 && pt_1>24 && pt_2>13)'\n",
    "trigger2312_18 = '(passMu23E12DZ && matchMu23E12DZ_1 && filterMu23E12DZ_1 && matchMu23E12DZ_2 && filterMu23E12DZ_2 && pt_1>13 && pt_2>24)'\n",
    "\n",
    "trigger_all_18 = trigger823_18 + str(' or ') + trigger2312_18\n",
    "\n",
    "for i in range(len(files18)):\n",
    "    files18[i] = files18[i].Filter('Flag_goodVertices==0')\\\n",
    "    .Filter('Flag_globalSuperTightHalo2016Filter==0')\\\n",
    "    .Filter('Flag_HBHENoiseFilter==0')\\\n",
    "    .Filter('Flag_HBHENoiseIsoFilter==0')\\\n",
    "    .Filter('Flag_EcalDeadCellTriggerPrimitiveFilter==0')\\\n",
    "    .Filter('Flag_BadPFMuonFilter==0')\\\n",
    "    .Filter('Flag_ecalBadCalibReducedMINIAODFilter==0')\\\n",
    "    .Filter('fabs(eta_1)<2.4 && fabs(eta_2)<2.4')\\\n",
    "    .Filter('iso_1<0.15 && iso_2<0.15')\\\n",
    "    .Filter('dR_tt>0.3')\n",
    "\n",
    "files18[0] = files18[0].Filter('Flag_eeBadScFilter==0')\n",
    "files18[2] = files18[2].Filter('Flag_eeBadScFilter==0')\n",
    "\n",
    "files18[3] = files18[3].Filter('(gen_match_1<3 or gen_match_1==6)')\n",
    "\n",
    "files18[1] = files18[1].Filter('gen_match_1==3 && gen_match_2==4')#recontructed taus are gen taus\n",
    "#files18[1] = files18[1].Filter('m_btt<200')#reject long tail (mostly wrongly reco b jet)\n",
    "\n",
    "files18[2] = files18[2].Filter('genweight<=1.0')\n",
    "\n",
    "# triggers\n",
    "files18[0] = files18[0].Filter(trigger_all_18)\n",
    "files18[1] = files18[1].Filter(trigger_all_18)\n",
    "files18[2] = files18[2].Filter(trigger_all_18)\n",
    "files18[3] = files18[3].Filter(trigger_all_18)\n",
    "\n",
    "# QCD region\n",
    "qcd_18 = files18[0].Filter('q_1*q_2>0')\n",
    "\n",
    "# signal region\n",
    "for i in range(1,len(files18)):\n",
    "    files18[i] = files18[i].Filter('q_1*q_2<0')\n",
    "\n",
    "######################## 2 0 1 7 ##########################\n",
    "# 2017 ele+mu trigger requirements \n",
    "trigger823_17 = '(passMu8E23DZ && matchMu8E23DZ_1 && filterMu8E23DZ_1 && matchMu8E23DZ_2 && filterMu8E23DZ_2 && pt_1>24 && pt_2>13)'\n",
    "trigger2312_17 = '(passMu23E12DZ && matchMu23E12DZ_1 && filterMu23E12DZ_1 && matchMu23E12DZ_2 && filterMu23E12DZ_2 && pt_1>13 && pt_2>24)'\n",
    "\n",
    "trigger_all_17 = trigger823_17 + str(' or ') + trigger2312_17\n",
    "\n",
    "for i in range(len(files17)):\n",
    "    files17[i] = files17[i].Filter('Flag_goodVertices==0')\\\n",
    "    .Filter('Flag_globalSuperTightHalo2016Filter==0')\\\n",
    "    .Filter('Flag_HBHENoiseFilter==0')\\\n",
    "    .Filter('Flag_HBHENoiseIsoFilter==0')\\\n",
    "    .Filter('Flag_EcalDeadCellTriggerPrimitiveFilter==0')\\\n",
    "    .Filter('Flag_BadPFMuonFilter==0')\\\n",
    "    .Filter('Flag_ecalBadCalibReducedMINIAODFilter==0')\\\n",
    "    .Filter('fabs(eta_1)<2.4 && fabs(eta_2)<2.4')\\\n",
    "    .Filter('iso_1<0.15 && iso_2<0.15')\\\n",
    "    .Filter('dR_tt>0.3')\n",
    "\n",
    "files17[0] = files17[0].Filter('Flag_eeBadScFilter==0')\n",
    "files17[2] = files17[2].Filter('Flag_eeBadScFilter==0')\n",
    "\n",
    "files17[3] = files17[3].Filter('(gen_match_1<3 or gen_match_1==6)')\n",
    "\n",
    "files17[1] = files17[1].Filter('gen_match_1==3 && gen_match_2==4')#recontructed taus are gen taus\n",
    "#files17[1] = files17[1].Filter('m_btt<200')#reject long tail (mostly wrongly reco b jet)\n",
    "\n",
    "files17[2] = files17[2].Filter('genweight<=1.0')\n",
    "\n",
    "# triggers\n",
    "files17[0] = files17[0].Filter(trigger_all_17)\n",
    "files17[1] = files17[1].Filter(trigger_all_17)\n",
    "files17[2] = files17[2].Filter(trigger_all_17)\n",
    "files17[3] = files17[3].Filter(trigger_all_17)\n",
    "\n",
    "# QCD region\n",
    "qcd_17 = files17[0].Filter('q_1*q_2>0')\n",
    "\n",
    "# signal region\n",
    "for i in range(1,len(files17)):\n",
    "    files17[i] = files17[i].Filter('q_1*q_2<0')\n",
    "\n",
    "######################## 2 0 1 6 ##########################\n",
    "# 2016 ele+mu trigger requirements\n",
    "trigger823_16 = '(passMu8E23 && matchMu8E23_1 && filterMu8E23_1 && matchMu8E23_2 && pt_1>24 && pt_2>13)'\n",
    "trigger2312_16 = '(passMu23E12 && matchMu23E12_1 && filterMu23E12_1 && matchMu23E12_2 && pt_1>13 && pt_2>24)'\n",
    "\n",
    "trigger_all_16 = trigger823_16 + str(' or ') + trigger2312_16\n",
    "\n",
    "for i in range(len(files16)):\n",
    "    files16[i] = files16[i].Filter('Flag_goodVertices==0')\\\n",
    "    .Filter('Flag_globalSuperTightHalo2016Filter==0')\\\n",
    "    .Filter('Flag_HBHENoiseFilter==0')\\\n",
    "    .Filter('Flag_HBHENoiseIsoFilter==0')\\\n",
    "    .Filter('Flag_EcalDeadCellTriggerPrimitiveFilter==0')\\\n",
    "    .Filter('Flag_BadPFMuonFilter==0')\\\n",
    "    .Filter('pt_2>20')\\\n",
    "    .Filter('fabs(eta_1)<2.1 && fabs(eta_2)<2.3')\\\n",
    "    .Filter('iso_1<0.15')\\\n",
    "    .Filter('byVLooseDeepVSmu_2 && byTightDeepVSe_2')\\\n",
    "    .Filter('dR_tt>0.4')\n",
    "\n",
    "files16[0] = files16[0].Filter('Flag_eeBadScFilter==0')\n",
    "files16[2] = files16[2].Filter('Flag_eeBadScFilter==0')\n",
    "\n",
    "files16[3] = files16[3].Filter('(gen_match_1<3 or gen_match_1==6)')\n",
    "\n",
    "files16[1] = files16[1].Filter('gen_match_1==3 && gen_match_2==4')#recontructed taus are gen taus\n",
    "#files16[1] = files16[1].Filter('m_btt<200')#reject long tail (mostly wrongly reco b jet)\n",
    "\n",
    "files16[2] = files16[2].Filter('genweight<=1.0')\n",
    "\n",
    "# triggers\n",
    "files16[0] = files16[0].Filter(trigger_all_16)\n",
    "files16[1] = files16[1].Filter(trigger_all_16)\n",
    "files16[2] = files16[2].Filter(trigger_all_16)\n",
    "files16[3] = files16[3].Filter(trigger_all_16)\n",
    "\n",
    "# QCD region\n",
    "qcd_16 = files16[0].Filter('q_1*q_2>0')\n",
    "\n",
    "# signal region\n",
    "for i in range(1,len(files16)):\n",
    "    files16[i] = files16[i].Filter('q_1*q_2<0')\n",
    "\n",
    "# [0]=obs, [1]=sig, [2]=embedded, [3]=ttbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select all input features and save into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list of feature variables\n",
    "###### for 1b events\n",
    "feature_list = ['pt_1', 'pt_2', 'm_btt', 'm_b1ele', 'm_b1mu',\\\n",
    "                'dR_tt', 'dR_b1ele', 'dR_b1mu', 'dR_b1tt',\\\n",
    "                'tt_pt', 'tt_eta', 'mT_ele', 'mT_mu', 'mT_b1', 'Dzeta',\\\n",
    "                'bpt_deepcsv_1', 'njets']\n",
    "\n",
    "# convert root RDataFrame into pandas DataFrame, saving only the features as columns\n",
    "for i in range(1,len(files18)):\n",
    "    files18[i] = pd.DataFrame(files18[i].AsNumpy(feature_list))\n",
    "    files17[i] = pd.DataFrame(files17[i].AsNumpy(feature_list))\n",
    "    files16[i] = pd.DataFrame(files16[i].AsNumpy(feature_list))\n",
    "qcd1_18 = pd.DataFrame(qcd1_18.AsNumpy(feature_list))\n",
    "qcd2_18 = pd.DataFrame(qcd2_18.AsNumpy(feature_list))\n",
    "qcd_17 = pd.DataFrame(qcd_17.AsNumpy(feature_list))\n",
    "qcd_16 = pd.DataFrame(qcd_16.AsNumpy(feature_list))\n",
    "\n",
    "print('sig18.shape  : ' + str(files18[1].shape))\n",
    "print('ZTT18.shape  : ' + str(files18[2].shape))\n",
    "print('TT18.shape   : ' + str(files18[3].shape))\n",
    "print('qcd18_1.shape: ' + str(qcd1_18.shape))\n",
    "print('qcd18_2.shape: ' + str(qcd2_18.shape))\n",
    "print('\\nsig17.shape  : ' + str(files17[1].shape))\n",
    "print('ZTT17.shape  : ' + str(files17[2].shape))\n",
    "print('TT17.shape   : ' + str(files17[3].shape))\n",
    "print('qcd17.shape  : ' + str(qcd_17.shape))\n",
    "print('\\nsig16.shape  : ' + str(files16[1].shape))\n",
    "print('ZTT16.shape  : ' + str(files16[2].shape))\n",
    "print('TT16.shape   : ' + str(files16[3].shape))\n",
    "print('qcd16.shape  : ' + str(qcd_16.shape))\n",
    "\n",
    "sig_allyears = [files18[1], files17[1], files16[1]]\n",
    "ZTT_allyears = [files18[2], files17[2], files16[2]]\n",
    "TT_allyears = [files18[3], files17[3], files16[3]]\n",
    "qcd_allyears = [qcd1_18, qcd2_18, qcd_17, qcd_16]\n",
    "\n",
    "sig_allyears = pd.concat(sig_allyears)\n",
    "ZTT_allyears = pd.concat(ZTT_allyears)\n",
    "TT_allyears = pd.concat(TT_allyears)\n",
    "qcd_allyears = pd.concat(qcd_allyears)\n",
    "\n",
    "# tag MC signal events as class 1\n",
    "sig_allyears['label'] = np.ones((sig_allyears.shape[0], 1))\n",
    "\n",
    "# tag MC background events as class 0\n",
    "ZTT_allyears['label'] = np.zeros((ZTT_allyears.shape[0], 1))\n",
    "TT_allyears['label'] = np.zeros((TT_allyears.shape[0],1))\n",
    "qcd_allyears['label'] = np.zeros((qcd_allyears.shape[0], 1))\n",
    "\n",
    "print('\\nsig_allyears.shape: ' + str(sig_allyears.shape))\n",
    "print('ZTT_allyears.shape: ' + str(ZTT_allyears.shape))\n",
    "print('TT_allyears.shape : ' + str(TT_allyears.shape))\n",
    "print('qcd_allyears.shape: ' + str(qcd_allyears.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into MC/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reduce class 0 sample size for balanced training\n",
    "ZTT_allyears = ZTT_allyears.sample(n = 2497, random_state = 20)#7153->3.1%->\n",
    "TT_allyears = TT_allyears.sample(n = 10249, random_state = 20)#216569->92.5%->\n",
    "qcd_allyears = qcd_allyears.sample(n = 7233, random_state = 20)#10363->4.4%->\n",
    "\n",
    "# collect all MC as one dataframe, separated from another datafream for observed data\n",
    "df_bkg = [ZTT_allyears, TT_allyears, qcd_allyears]\n",
    "df_bkg = pd.concat(df_bkg)\n",
    "\n",
    "df_MC = [sig_allyears, ZTT_allyears, TT_allyears, qcd_allyears]\n",
    "df_MC = pd.concat(df_MC)\n",
    "\n",
    "#print('\\nObserved dataframe: \\n' + str(df_obs))\n",
    "print('\\nMC dataframe: \\n' + str(df_MC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare input feature distributions between sig and bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyplot.hist(sig_allyears['pt_1'], density = 1, range = (0,120), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['pt_1'], density = 1, range = (0,120), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['pt_1'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['pt_1'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['pt_1'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('e pt (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['pt_2'], density = 1, range = (0,120), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['pt_2'], density = 1, range = (0,120), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['pt_2'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['pt_2'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['pt_2'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('$\\mu$ pt (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['m_btt'], density = 1, range = (30,450), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['m_btt'], density = 1, range = (30,450), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['m_btt'], density = 1, range = (30,450), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['m_btt'], density = 1, range = (30,450), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['m_btt'], density = 1, range = (30,450), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('m_b$\\\\tau\\\\tau$ (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['m_b1ele'], density = 1, range = (0,200), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['m_b1ele'], density = 1, range = (0,200), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['m_b1ele'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['m_b1ele'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['m_b1ele'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('m_b$_1$e (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['m_b1mu'], density = 1, range = (0,200), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['m_b1mu'], density = 1, range = (0,200), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['m_b1mu'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['m_b1mu'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['m_b1mu'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('m_b$_1$$\\mu$ (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['dR_tt'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['dR_tt'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['dR_tt'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['dR_tt'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['dR_tt'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('dR(e,$\\mu$)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['dR_b1ele'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['dR_b1ele'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['dR_b1ele'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['dR_b1ele'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['dR_b1ele'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('dR(b$_1$,e)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['dR_b1mu'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['dR_b1mu'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['dR_b1mu'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['dR_b1mu'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['dR_b1mu'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('dR(b$_1$,$\\mu$)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['dR_b1tt'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['dR_b1tt'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['dR_b1tt'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['dR_b1tt'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['dR_b1tt'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('dR(b$_1$,$\\\\tau\\\\tau$)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['tt_pt'], density = 1, range = (0,250), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['tt_pt'], density = 1, range = (0,250), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['tt_pt'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['tt_pt'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['tt_pt'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('$\\\\tau\\\\tau$ pt (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['tt_eta'], density = 1, range = (-2.4,2.4), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['tt_eta'], density = 1, range = (-2.4,2.4), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['tt_eta'], density = 1, range = (-2.4,2.4), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['tt_eta'], density = 1, range = (-2.4,2.4), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['tt_eta'], density = 1, range = (-2.4,2.4), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('$\\\\tau\\\\tau$ $\\eta$')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['mT_ele'], density = 1, range = (0,250), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['mT_ele'], density = 1, range = (0,250), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['mT_ele'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['mT_ele'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['mT_ele'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('mT(e,met) (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['mT_mu'], density = 1, range = (0,250), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['mT_mu'], density = 1, range = (0,250), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['mT_mu'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['mT_mu'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['mT_mu'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('mT($\\mu$,met) (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['mT_b1'], density = 1, range = (0,250), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['mT_b1'], density = 1, range = (0,250), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['mT_b1'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['mT_b1'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['mT_b1'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('mT(b$_1$,met) (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['Dzeta'], density = 1, range = (-200,120), bins = 50, alpha = 0.3, label = 'h->aa->bb$\\\\tau\\\\tau$')\n",
    "pyplot.hist(df_bkg['Dzeta'], density = 1, range = (-200,120), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['Dzeta'], density = 1, range = (-200,120), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['Dzeta'], density = 1, range = (-200,120), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['Dzeta'], density = 1, range = (-200,120), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('$D_\\zeta$ (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['bpt_deepcsv_1'], density = 1, range = (10,130), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(df_bkg['bpt_deepcsv_1'], density = 1, range = (10,130), bins = 50, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['bpt_deepcsv_1'], density = 1, range = (10,130), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['bpt_deepcsv_1'], density = 1, range = (10,130), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['bpt_deepcsv_1'], density = 1, range = (10,130), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('Leading b jet pt (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(sig_allyears['njets'], density = 1, range = (0,8), bins = 8, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(df_bkg['njets'], density = 1, range = (0,8), bins = 8, alpha = 0.3, label = 'bkg (ZTT, ttbar, QCD)')\n",
    "#pyplot.hist(ZTT_allyears['njets'], density = 1, range = (0,8), bins = 8, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "#pyplot.hist(TT_allyears['njets'], density = 1, range = (0,8), bins = 8, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "#pyplot.hist(qcd_allyears['njets'], density = 1, range = (0,8), bins = 8, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('njets')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "dataset = df_MC.values\n",
    "X = dataset[:,0:(dataset.shape[1]-1)]\n",
    "Y = dataset[:,dataset.shape[1]-1]\n",
    "Y = Y.reshape(Y.shape[0],1)\n",
    "\n",
    "#dataset_obs = df_obs.values\n",
    "#X_obs = dataset_obs[:,0:(dataset_obs.shape[1])]\n",
    "\n",
    "# give train/val/test partition ratios\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "\n",
    "# randomly partition data set into train/val/test sets with given ratios\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size = test_ratio, random_state=15)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = val_ratio/(val_ratio+train_ratio), random_state=15)\n",
    "\n",
    "# standardize feature variables\n",
    "# only based on means and stds in train_val set, should apply this only scaler to all other sets\n",
    "# think of the transformation in phase space\n",
    "scaler = StandardScaler().fit(X_train_val)\n",
    "X_train_val = scaler.transform(X_train_val)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "#X_obs = scaler.transform(X_obs)\n",
    "\n",
    "# print input data shapes\n",
    "print(\"\\nPartition the data set into train/val/test: %.2f/%.2f/%.2f\" % (train_ratio, val_ratio, test_ratio))\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"Y_train.shape: \" + str(Y_train.shape))\n",
    "print(\"X_val.shape: \" + str(X_val.shape))\n",
    "print(\"Y_val.shape: \" + str(Y_val.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))\n",
    "print(\"Y_test.shape: \" + str(Y_test.shape))\n",
    "#print(\"\\nX_obs.shape: \" + str(X_obs.shape))\n",
    "\n",
    "# print ratio of signal/background examples in each set\n",
    "train_sig = np.count_nonzero(Y_train)\n",
    "train_bkg = np.count_nonzero(Y_train == 0)\n",
    "train_sig_perc = 100*train_sig/(train_sig+train_bkg)\n",
    "train_bkg_perc = 100*train_bkg/(train_sig+train_bkg)\n",
    "val_sig = np.count_nonzero(Y_val)\n",
    "val_bkg = np.count_nonzero(Y_val == 0)\n",
    "val_sig_perc = 100*val_sig/(val_sig+val_bkg)\n",
    "val_bkg_perc = 100*val_bkg/(val_sig+val_bkg)\n",
    "test_sig = np.count_nonzero(Y_test)\n",
    "test_bkg = np.count_nonzero(Y_test == 0)\n",
    "test_sig_perc = 100*test_sig/(test_sig+test_bkg)\n",
    "test_bkg_perc = 100*test_bkg/(test_sig+test_bkg)\n",
    "\n",
    "total_sig = train_sig + val_sig + test_sig\n",
    "total_bkg = train_bkg + val_bkg + test_bkg\n",
    "total_sig_perc = 100*total_sig/(total_sig+total_bkg)\n",
    "total_bkg_perc = 100*total_bkg/(total_sig+total_bkg)\n",
    "print(\"\\nTotal number of sig/bkg examples: %d/%d (%.2f%%/%.2f%%)\" % (total_sig, total_bkg, total_sig_perc, total_bkg_perc))\n",
    "\n",
    "print(\"\\nNumber of sig/bkg examples in each set:\")\n",
    "print(\"train : %d/%d (%.1f%%/%.1f%%)\" % (train_sig, train_bkg, train_sig_perc, train_bkg_perc))\n",
    "print(\"val   : %d/%d (%.1f%%/%.1f%%)\" % (val_sig, val_bkg, val_sig_perc, val_bkg_perc))\n",
    "print(\"test  : %d/%d (%.1f%%/%.1f%%)\" % (test_sig, test_bkg, test_sig_perc, test_bkg_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN Hyperparameters searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for the search\n",
    "def hypermodel(hp):\n",
    "    hp_model = keras.Sequential()\n",
    "    hp_model.add(keras.layers.Input(shape = (X.shape[1],)))\n",
    "    \n",
    "    hp_model.add(keras.layers.Dense(units = hp.Int('units_1',\n",
    "                                                   min_value = 20,\n",
    "                                                   max_value = 60,\n",
    "                                                   step = 2),\n",
    "                                    activation = 'relu',\n",
    "                                    kernel_initializer = glorot_uniform(seed=1)))\n",
    "    \n",
    "    hp_model.add(keras.layers.Dropout(rate = hp.Float('rate_1',\n",
    "                                                      min_value = 0.2,\n",
    "                                                      max_value = 0.5,\n",
    "                                                      default = 0.2,\n",
    "                                                      step = 0.1),\n",
    "                                      seed = 10))\n",
    "    \n",
    "    hp_model.add(keras.layers.Dense(units = hp.Int('units_2',\n",
    "                                                   min_value = 20,\n",
    "                                                   max_value = 60,\n",
    "                                                   step = 2),\n",
    "                                    activation = 'relu',\n",
    "                                    kernel_initializer = glorot_uniform(seed=1)))\n",
    "    \n",
    "    hp_model.add(keras.layers.Dropout(rate = hp.Float('rate_2',\n",
    "                                                      min_value = 0.2,\n",
    "                                                      max_value = 0.5,\n",
    "                                                      default = 0.2,\n",
    "                                                      step = 0.1),\n",
    "                                      seed = 10))\n",
    "\n",
    "    hp_model.add(keras.layers.Dense(units = 1, activation = 'sigmoid', kernel_initializer = glorot_uniform(seed=1)))\n",
    "    hp_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return hp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tuner model\n",
    "tuner = Hyperband(hypermodel,\n",
    "                  objective = 'val_accuracy',\n",
    "                  max_epochs = 20,\n",
    "                  factor = 3, #number of models to train in a bracket = 1+log_factor(max_epochs)\n",
    "                  hyperband_iterations = 1, #number of times to iterate over the full Hyperband algorithm\n",
    "                  seed = 10,\n",
    "                  directory = 'hypertuning',\n",
    "                  project_name = 'tune',\n",
    "                  overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run the search\n",
    "tuner.search(X_train, Y_train, epochs = 20, validation_data = (X_val,Y_val), batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## input layer ########\n",
    "X_input = Input(shape = (X.shape[1],), name = 'X_input')\n",
    "\n",
    "######## hidden layers ########\n",
    "hidden_1 = Dense(\n",
    "    units = 52,\n",
    "    activation = 'relu',\n",
    "    kernel_initializer = glorot_uniform(seed=1),\n",
    "    name = 'Hidden_layer_1'\n",
    ")(X_input)\n",
    "\n",
    "dropout_1 = Dropout(rate = 0.2, seed = 10, name = 'Dropout_layer_1')(hidden_1)\n",
    "\n",
    "hidden_2 = Dense(\n",
    "    units = 36,\n",
    "    activation = 'relu',\n",
    "    kernel_initializer = glorot_uniform(seed=1),\n",
    "    name = 'Hidden_layer_2'\n",
    ")(dropout_1)\n",
    "\n",
    "dropout_2 = Dropout(rate = 0.2, seed = 10, name = 'Dropout_layer_2')(hidden_2)\n",
    "\n",
    "######## output layer #######\n",
    "Y_output = Dense(\n",
    "    units = 1,\n",
    "    activation = 'sigmoid',\n",
    "    kernel_initializer = glorot_uniform(seed=1),\n",
    "    name = 'Y_output'\n",
    ")(dropout_2)\n",
    "\n",
    "\n",
    "model = Model(inputs = X_input, outputs = Y_output)\n",
    "\n",
    "# use adaptive moment estimation (adam) to train, which uses both GD with momentum and RMSprop\n",
    "# the default hyperparameters in adam are usually good enough\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) ### accuracy = freq. of y_pred = y_true\n",
    "\n",
    "# show model details\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1 epoch = 1 pass through the data set\n",
    "# typical mini-batch size = 2^n for faster computation\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs = 15,\n",
    "                    validation_data = (X_val, Y_val),\n",
    "                    batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/validation performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss vs epoch\n",
    "plt.figure(figsize = (15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label = 'train loss')\n",
    "axes.plot(history.history['val_loss'], label = 'val loss')\n",
    "axes.legend(loc = \"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')\n",
    "\n",
    "# plot accuracy vs epoch\n",
    "axes = plt.subplot(2, 2, 2)\n",
    "axes.plot(history.history['accuracy'], label = 'train accuracy')\n",
    "axes.plot(history.history['val_accuracy'], label = 'val accuracy')\n",
    "axes.legend(loc = \"lower right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Accuracy (y_pred = y_true)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the test set into sig/bkg sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "test_sig_number = np.count_nonzero(Y_test)\n",
    "test_bkg_number = np.count_nonzero(Y_test == 0)\n",
    "\n",
    "X_test_sig = np.zeros((test_sig_number,X_test.shape[1]))\n",
    "X_test_bkg = np.zeros((test_bkg_number,X_test.shape[1]))\n",
    "\n",
    "j = 0\n",
    "k = 0\n",
    "for i in range(Y_test.shape[0]):\n",
    "    if Y_test[i,0] == 1:\n",
    "        X_test_sig[j,:] = X_test[i,:]\n",
    "        j = j + 1\n",
    "    else:\n",
    "        X_test_bkg[k,:] = X_test[i,:]\n",
    "        k = k + 1\n",
    "\n",
    "# train+val set\n",
    "train_val_sig_number = np.count_nonzero(Y_train_val)\n",
    "train_val_bkg_number = np.count_nonzero(Y_train_val == 0)\n",
    "\n",
    "X_train_val_sig = np.zeros((train_val_sig_number,X_train_val.shape[1]))\n",
    "X_train_val_bkg = np.zeros((train_val_bkg_number,X_train_val.shape[1]))\n",
    "\n",
    "j = 0\n",
    "k = 0\n",
    "for i in range(Y_train_val.shape[0]):\n",
    "    if Y_train_val[i,0] == 1:\n",
    "        X_train_val_sig[j,:] = X_train_val[i,:]\n",
    "        j = j + 1\n",
    "    else:\n",
    "        X_train_val_bkg[k,:] = X_train_val[i,:]\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pyplot.hist(model.predict(X_test_bkg), density = 1, range = (0.0, 1.0), bins = 40, alpha = 0.3, label = 'Bkg (test)')\n",
    "pyplot.hist(model.predict(X_test_bkg), density = 1, range = (0.0, 1.0), bins = 40, alpha = 0.3, label = 'Bkg (test)', log = True)\n",
    "pyplot.hist(model.predict(X_test_sig), density = 1, range = (0.0, 1.0), bins = 40, alpha = 0.3, label = 'Sig (test)')\n",
    "pyplot.hist(model.predict(X_train_val_bkg), density = 1, range = (0.0, 1.0), bins = 40, label = 'Bkg (train+val)', histtype = 'step')\n",
    "pyplot.hist(model.predict(X_train_val_sig), density = 1, range = (0.0, 1.0), bins = 40, label = 'Sig (train+val)', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper center')\n",
    "pyplot.title('DNN output (unweighted, normalized)')\n",
    "pyplot.xlabel('Signal probability p')\n",
    "pyplot.xticks(np.arange(0, 1.1, step = 0.1))\n",
    "pyplot.ylim(1e-2,1e2)\n",
    "pyplot.show()\n",
    "\n",
    "#pyplot.hist(np.arctanh(model.predict(X_test_bkg)*np.tanh(1)), density = 1, range = (0.0, 1), bins = 40, alpha = 0.3, label = 'Bkg (test)')\n",
    "pyplot.hist(np.arctanh(model.predict(X_test_bkg)*np.tanh(1)), density = 1, range = (0.0, 1), bins = 40, alpha = 0.3, label = 'Bkg (test)', log = True)\n",
    "pyplot.hist(np.arctanh(model.predict(X_test_sig)*np.tanh(1)), density = 1, range = (0.0, 1), bins = 40, alpha = 0.3, label = 'Sig (test)')\n",
    "pyplot.hist(np.arctanh(model.predict(X_train_val_bkg)*np.tanh(1)), density = 1, range = (0.0, 1), bins = 40, label = 'Bkg (train+val)', histtype = 'step')\n",
    "pyplot.hist(np.arctanh(model.predict(X_train_val_sig)*np.tanh(1)), density = 1, range = (0.0, 1), bins = 40, label = 'Sig (train+val)', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper center')\n",
    "pyplot.title('Transformed DNN output (unweighted, normalized)')\n",
    "pyplot.xlabel('arctanh(p*tanh(1))')\n",
    "pyplot.xticks(np.arange(0, 1.1, step = 0.1))\n",
    "pyplot.ylim(1e-2,1e2)\n",
    "pyplot.show()\n",
    "\n",
    "#pyplot.hist(np.arctanh(model.predict(X_test_bkg)*np.tanh(2))/2, density = 1, range = (0.0, 1), bins = 40, alpha = 0.3, label = 'Bkg (test)')\n",
    "pyplot.hist(np.arctanh(model.predict(X_test_bkg)*np.tanh(2))/2, density = 1, range = (0.0, 1), bins = 40, alpha = 0.3, label = 'Bkg (test)', log = True)\n",
    "pyplot.hist(np.arctanh(model.predict(X_test_sig)*np.tanh(2))/2, density = 1, range = (0.0, 1), bins = 40, alpha = 0.3, label = 'Sig (test)')\n",
    "pyplot.hist(np.arctanh(model.predict(X_train_val_bkg)*np.tanh(2))/2, density = 1, range = (0.0, 1), bins = 40, label = 'Bkg (train+val)', histtype = 'step')\n",
    "pyplot.hist(np.arctanh(model.predict(X_train_val_sig)*np.tanh(2))/2, density = 1, range = (0.0, 1), bins = 40, label = 'Sig (train+val)', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper center')\n",
    "pyplot.title('Transformed DNN output (unweighted, normalized)')\n",
    "pyplot.xlabel('arctanh(p*tanh(2))/2')\n",
    "pyplot.xticks(np.arange(0, 1.1, step = 0.1))\n",
    "pyplot.ylim(1e-2,1e2)\n",
    "pyplot.show()\n",
    "\n",
    "#pyplot.hist(np.arctanh(model.predict(X_test_bkg)*np.tanh(3))/3, density = 1, range = (0.0, 1), bins = 40, alpha = 0.3, label = 'Bkg (test)')\n",
    "pyplot.hist(np.arctanh(model.predict(X_test_bkg)*np.tanh(3))/3, density = 1, range = (0.0, 1), bins = 40, alpha = 0.3, label = 'Bkg (test)', log = True)\n",
    "pyplot.hist(np.arctanh(model.predict(X_test_sig)*np.tanh(3))/3, density = 1, range = (0.0, 1), bins = 40, alpha = 0.3, label = 'Sig (test)')\n",
    "pyplot.hist(np.arctanh(model.predict(X_train_val_bkg)*np.tanh(3))/3, density = 1, range = (0.0, 1), bins = 40, label = 'Bkg (train+val)', histtype = 'step')\n",
    "pyplot.hist(np.arctanh(model.predict(X_train_val_sig)*np.tanh(3))/3, density = 1, range = (0.0, 1), bins = 40, label = 'Sig (train+val)', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper center')\n",
    "pyplot.title('Transformed DNN output (unweighted, normalized)')\n",
    "pyplot.xlabel('arctanh(p*tanh(3))/3')\n",
    "pyplot.xticks(np.arange(0, 1.1, step = 0.1))\n",
    "pyplot.ylim(1e-2,1e2)\n",
    "pyplot.show()\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure(figsize = (13,13))\n",
    "Y_predict = model.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_predict)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(fpr, tpr, lw = 2, color = 'red', label = 'ROC curve for test set, AUC = %.3f' % (roc_auc))\n",
    "axes.plot([0, 1], [0, 1], linestyle = '--', lw = 2, color = 'black', label = 'random chance')\n",
    "axes.set_xlim([0, 1.0])\n",
    "axes.set_ylim([0, 1.0])\n",
    "axes.set_xlabel('Fake signal rate (FPR)')\n",
    "axes.set_ylabel('True signal rate (TPR)')\n",
    "axes.set_title('Receiver operating characteristic (ROC)')\n",
    "axes.legend(loc = \"lower right\")\n",
    "plt.show()\n",
    "\n",
    "results = model.evaluate(X_test, Y_test, verbose = 0, batch_size = 256)\n",
    "print(\"Test loss, test accuracy:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(scaler, 'trained_models/em1b_scaler.gz')\n",
    "model.save('trained_models/em1b_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedscaler = joblib.load('trained_models/em1b_scaler.gz')\n",
    "savedmodel = keras.models.load_model('trained_models/em1b_model')\n",
    "savedmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write model prediction to root files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all root files one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from root_numpy import array2root\n",
    "\n",
    "########### 2018\n",
    "infolder18 = 'root_raw/em18_raw/'\n",
    "outfolder18 = 'root_outputs/em18_outputs/'\n",
    "\n",
    "inpaths18 = ['DY.root', 'DY1.root', 'DY2.root', 'DY3.root', 'DY4.root'\\\n",
    "         , 'GGHTT.root', 'GGHWW.root', 'GGZHLLTT.root', 'GGZHNNTT.root'\\\n",
    "         , 'GGZHQQTT.root', 'GGZHWW.root', 'ST_tW_antitop.root'\\\n",
    "         , 'ST_tW_top.root', 'ST_t_antitop.root', 'ST_t_top.root'\\\n",
    "         , 'TTTo2L2Nu.root', 'TTToHadronic.root', 'TTToSemiLeptonic.root', 'VBFHTT.root', 'VBFHWW.root', 'VV2L2Nu.root'\\\n",
    "         , 'WZ2L2Q.root', 'WZ3LNu.root', 'WminusHTT.root', 'WminusHWW.root'\\\n",
    "         , 'WplusHTT.root', 'WplusHWW.root', 'ZHTT.root', 'ZHWW.root'\\\n",
    "         , 'ZZ2L2Q.root', 'ZZ4L.root', 'data_obs.root', 'embedded.root'\\\n",
    "         , 'ggH_bbtt12.root', 'ggH_bbtt20.root', 'ggH_bbtt30.root', 'ggH_bbtt40.root'\\\n",
    "         , 'ggH_bbtt50.root', 'ggH_bbtt60.root', 'ttHnonbb.root'\\\n",
    "         , 'vbf_bbtt12.root', 'vbf_bbtt20.root', 'vbf_bbtt30.root', 'vbf_bbtt40.root'\\\n",
    "         , 'vbf_bbtt50.root', 'vbf_bbtt60.root']\n",
    "\n",
    "outpaths18 = ['DY.root', 'DY1.root', 'DY2.root', 'DY3.root', 'DY4.root'\\\n",
    "         , 'GGHTT.root', 'GGHWW.root', 'GGZHLLTT.root', 'GGZHNNTT.root'\\\n",
    "         , 'GGZHQQTT.root', 'GGZHWW.root', 'ST_tW_antitop.root'\\\n",
    "         , 'ST_tW_top.root', 'ST_t_antitop.root', 'ST_t_top.root'\\\n",
    "         , 'TTTo2L2Nu.root', 'TTToHadronic.root', 'TTToSemiLeptonic.root', 'VBFHTT.root', 'VBFHWW.root', 'VV2L2Nu.root'\\\n",
    "         , 'WZ2L2Q.root', 'WZ3LNu.root', 'WminusHTT.root', 'WminusHWW.root'\\\n",
    "         , 'WplusHTT.root', 'WplusHWW.root', 'ZHTT.root', 'ZHWW.root'\\\n",
    "         , 'ZZ2L2Q.root', 'ZZ4L.root', 'data_obs.root', 'embedded.root'\\\n",
    "         , 'gghbbtt12.root', 'gghbbtt20.root', 'gghbbtt30.root', 'gghbbtt40.root'\\\n",
    "         , 'gghbbtt50.root', 'gghbbtt60.root', 'ttHnonbb.root'\\\n",
    "         , 'vbfbbtt12.root', 'vbfbbtt20.root', 'vbfbbtt30.root', 'vbfbbtt40.root'\\\n",
    "         , 'vbfbbtt50.root', 'vbfbbtt60.root']\n",
    "\n",
    "for i in range(len(inpaths18)):\n",
    "    inpaths18[i] = infolder18 + inpaths18[i]\n",
    "    outpaths18[i] = outfolder18 + outpaths18[i]\n",
    "\n",
    "allfiles18 = []\n",
    "for i in range(len(inpaths18)):\n",
    "    allfiles18.append(ROOT.RDataFrame('emu_tree', inpaths18[i]))\n",
    "\n",
    "\n",
    "for i in range(len(allfiles18)):\n",
    "    allfiles18[i] = allfiles18[i].Define('myele', myele)\\\n",
    "    .Define('mymu', mymu)\\\n",
    "    .Define('mymet', mymet)\\\n",
    "    .Define('mytt', mytt)\\\n",
    "    .Define('myb1', myb1)\\\n",
    "    .Define('m_btt', m_btt)\\\n",
    "    .Define('m_b1ele', m_b1ele)\\\n",
    "    .Define('m_b1mu', m_b1mu)\\\n",
    "    .Define('dR_tt', dR_tt)\\\n",
    "    .Define('dR_b1ele', dR_b1ele)\\\n",
    "    .Define('dR_b1mu', dR_b1mu)\\\n",
    "    .Define('dR_b1tt', dR_b1tt)\\\n",
    "    .Define('tt_pt', tt_pt)\\\n",
    "    .Define('tt_eta', tt_eta)\\\n",
    "    .Define('mT_ele', mT_ele)\\\n",
    "    .Define('mT_mu', mT_mu)\\\n",
    "    .Define('mT_b1', mT_b1)\\\n",
    "    .Define('norm_zeta', norm_zeta)\\\n",
    "    .Define('x_zeta', x_zeta)\\\n",
    "    .Define('y_zeta', y_zeta)\\\n",
    "    .Define('p_zeta_mis', p_zeta_mis)\\\n",
    "    .Define('pzeta_vis', pzeta_vis)\\\n",
    "    .Define('Dzeta', Dzeta)_vis)\\\n",
    "    .Define('Dzeta', Dzeta)\n",
    "\n",
    "########### 2017\n",
    "infolder17 = 'root_raw/em17_raw/'\n",
    "outfolder17 = 'root_outputs/em17_outputs/'\n",
    "\n",
    "inpaths17 = ['DY.root', 'DY1.root', 'DY2.root', 'DY3.root', 'DY4.root'\\\n",
    "         , 'GGHTT.root', 'GGHWW.root', 'GGZHLLTT.root', 'GGZHNNTT.root'\\\n",
    "         , 'GGZHQQTT.root', 'GGZHWW.root', 'ST_tW_antitop.root'\\\n",
    "         , 'ST_tW_top.root', 'ST_t_antitop.root', 'ST_t_top.root'\\\n",
    "         , 'TTTo2L2Nu.root', 'TTToHadronic.root', 'TTToSemiLeptonic.root', 'VBFHTT.root', 'VBFHWW.root', 'VV2L2Nu.root'\\\n",
    "         , 'WZ2L2Q.root', 'WZ3L1Nu.root', 'WminusHTT.root', 'WminusHWW.root'\\\n",
    "         , 'WplusHTT.root', 'WplusHWW.root', 'ZHTT.root', 'ZHWW.root'\\\n",
    "         , 'ZZ2L2Q.root', 'ZZ4L.root', 'data_obs.root', 'embedded.root'\\\n",
    "         , 'ggH_bbtt12.root', 'ggH_bbtt20.root', 'ggH_bbtt30.root', 'ggH_bbtt40.root'\\\n",
    "         , 'ggH_bbtt50.root', 'ggH_bbtt60.root', 'ttHnonbb.root'\\\n",
    "         , 'vbf_bbtt12.root', 'vbf_bbtt20.root', 'vbf_bbtt30.root', 'vbf_bbtt40.root'\\\n",
    "         , 'vbf_bbtt50.root', 'vbf_bbtt60.root']\n",
    "\n",
    "outpaths17 = ['DY.root', 'DY1.root', 'DY2.root', 'DY3.root', 'DY4.root'\\\n",
    "         , 'GGHTT.root', 'GGHWW.root', 'GGZHLLTT.root', 'GGZHNNTT.root'\\\n",
    "         , 'GGZHQQTT.root', 'GGZHWW.root', 'ST_tW_antitop.root'\\\n",
    "         , 'ST_tW_top.root', 'ST_t_antitop.root', 'ST_t_top.root'\\\n",
    "         , 'TTTo2L2Nu.root', 'TTToHadronic.root', 'TTToSemiLeptonic.root', 'VBFHTT.root', 'VBFHWW.root', 'VV2L2Nu.root'\\\n",
    "         , 'WZ2L2Q.root', 'WZ3L1Nu.root', 'WminusHTT.root', 'WminusHWW.root'\\\n",
    "         , 'WplusHTT.root', 'WplusHWW.root', 'ZHTT.root', 'ZHWW.root'\\\n",
    "         , 'ZZ2L2Q.root', 'ZZ4L.root', 'data_obs.root', 'embedded.root'\\\n",
    "         , 'gghbbtt12.root', 'gghbbtt20.root', 'gghbbtt30.root', 'gghbbtt40.root'\\\n",
    "         , 'gghbbtt50.root', 'gghbbtt60.root', 'ttHnonbb.root'\\\n",
    "         , 'vbfbbtt12.root', 'vbfbbtt20.root', 'vbfbbtt30.root', 'vbfbbtt40.root'\\\n",
    "         , 'vbfbbtt50.root', 'vbfbbtt60.root']\n",
    "\n",
    "for i in range(len(inpaths17)):\n",
    "    inpaths17[i] = infolder17 + inpaths17[i]\n",
    "    outpaths17[i] = outfolder17 + outpaths17[i]\n",
    "\n",
    "allfiles17 = []\n",
    "for i in range(len(inpaths17)):\n",
    "    allfiles17.append(ROOT.RDataFrame('emu_tree', inpaths17[i]))\n",
    "\n",
    "\n",
    "for i in range(len(allfiles17)):\n",
    "    allfiles17[i] = allfiles17[i].Define('myele', myele)\\\n",
    "    .Define('mymu', mymu)\\\n",
    "    .Define('mymet', mymet)\\\n",
    "    .Define('mytt', mytt)\\\n",
    "    .Define('myb1', myb1)\\\n",
    "    .Define('m_btt', m_btt)\\\n",
    "    .Define('m_b1ele', m_b1ele)\\\n",
    "    .Define('m_b1mu', m_b1mu)\\\n",
    "    .Define('dR_tt', dR_tt)\\\n",
    "    .Define('dR_b1ele', dR_b1ele)\\\n",
    "    .Define('dR_b1mu', dR_b1mu)\\\n",
    "    .Define('dR_b1tt', dR_b1tt)\\\n",
    "    .Define('tt_pt', tt_pt)\\\n",
    "    .Define('tt_eta', tt_eta)\\\n",
    "    .Define('mT_ele', mT_ele)\\\n",
    "    .Define('mT_mu', mT_mu)\\\n",
    "    .Define('mT_b1', mT_b1)\\\n",
    "    .Define('norm_zeta', norm_zeta)\\\n",
    "    .Define('x_zeta', x_zeta)\\\n",
    "    .Define('y_zeta', y_zeta)\\\n",
    "    .Define('p_zeta_mis', p_zeta_mis)\\\n",
    "    .Define('pzeta_vis', pzeta_vis)\\\n",
    "    .Define('Dzeta', Dzeta)\n",
    "\n",
    "########### 2016\n",
    "infolder16 = 'root_raw/em16_raw/'\n",
    "outfolder16 = 'root_outputs/em16_outputs/'\n",
    "\n",
    "inpaths16 = ['DY.root', 'DY1.root', 'DY2.root', 'DY3.root', 'DY4.root'\\\n",
    "         , 'GGHTT.root', 'GGHWW.root', 'GGZHLLTT.root', 'GGZHNNTT.root'\\\n",
    "         , 'GGZHQQTT.root', 'GGZHWW.root', 'ST_tW_antitop.root'\\\n",
    "         , 'ST_tW_top.root', 'ST_t_antitop.root', 'ST_t_top.root'\\\n",
    "         , 'TT.root', 'VBFHTT.root', 'VBFHWW.root', 'VV2L2Nu.root'\\\n",
    "         , 'WZ2L2Q.root', 'WZ3L1Nu.root', 'WminusHTT.root', 'WminusHWW.root'\\\n",
    "         , 'WplusHTT.root', 'WplusHWW.root', 'ZHTT.root', 'ZHWW.root'\\\n",
    "         , 'ZZ2L2Q.root', 'ZZ4L.root', 'data_obs.root', 'embedded.root'\\\n",
    "         , 'ggH_bbtt15.root', 'ggH_bbtt20.root', 'ggH_bbtt25.root', 'ggH_bbtt30.root', 'ggH_bbtt35.root', 'ggH_bbtt40.root'\\\n",
    "         , 'ggH_bbtt45.root', 'ggH_bbtt50.root', 'ggH_bbtt55.root', 'ggH_bbtt60.root', 'ttHnonbb.root'\\\n",
    "         , 'vbf_bbtt15.root', 'vbf_bbtt20.root', 'vbf_bbtt25.root', 'vbf_bbtt30.root', 'vbf_bbtt35.root', 'vbf_bbtt40.root'\\\n",
    "         , 'vbf_bbtt45.root', 'vbf_bbtt50.root', 'vbf_bbtt55.root', 'vbf_bbtt60.root']\n",
    "\n",
    "outpaths16 = ['DY.root', 'DY1.root', 'DY2.root', 'DY3.root', 'DY4.root'\\\n",
    "         , 'GGHTT.root', 'GGHWW.root', 'GGZHLLTT.root', 'GGZHNNTT.root'\\\n",
    "         , 'GGZHQQTT.root', 'GGZHWW.root', 'ST_tW_antitop.root'\\\n",
    "         , 'ST_tW_top.root', 'ST_t_antitop.root', 'ST_t_top.root'\\\n",
    "         , 'TT.root', 'VBFHTT.root', 'VBFHWW.root', 'VV2L2Nu.root'\\\n",
    "         , 'WZ2L2Q.root', 'WZ3L1Nu.root', 'WminusHTT.root', 'WminusHWW.root'\\\n",
    "         , 'WplusHTT.root', 'WplusHWW.root', 'ZHTT.root', 'ZHWW.root'\\\n",
    "         , 'ZZ2L2Q.root', 'ZZ4L.root', 'data_obs.root', 'embedded.root'\\\n",
    "         , 'ggH_bbtt15.root', 'ggH_bbtt20.root', 'ggH_bbtt25.root', 'ggH_bbtt30.root', 'ggH_bbtt35.root', 'ggH_bbtt40.root'\\\n",
    "         , 'ggH_bbtt45.root', 'ggH_bbtt50.root', 'ggH_bbtt55.root', 'ggH_bbtt60.root', 'ttHnonbb.root'\\\n",
    "         , 'vbf_bbtt15.root', 'vbf_bbtt20.root', 'vbf_bbtt25.root', 'vbf_bbtt30.root', 'vbf_bbtt35.root', 'vbf_bbtt40.root'\\\n",
    "         , 'vbf_bbtt45.root', 'vbf_bbtt50.root', 'vbf_bbtt55.root', 'vbf_bbtt60.root']\n",
    "\n",
    "for i in range(len(inpaths16)):\n",
    "    inpaths16[i] = infolder16 + inpaths16[i]\n",
    "    outpaths16[i] = outfolder16 + outpaths16[i]\n",
    "\n",
    "allfiles16 = []\n",
    "for i in range(len(inpaths16)):\n",
    "    allfiles16.append(ROOT.RDataFrame('emu_tree', inpaths16[i]))\n",
    "\n",
    "\n",
    "for i in range(len(allfiles16)):\n",
    "    allfiles16[i] = allfiles16[i].Define('myele', myele)\\\n",
    "    .Define('mymu', mymu)\\\n",
    "    .Define('mymet', mymet)\\\n",
    "    .Define('mytt', mytt)\\\n",
    "    .Define('myb1', myb1)\\\n",
    "    .Define('m_btt', m_btt)\\\n",
    "    .Define('m_b1ele', m_b1ele)\\\n",
    "    .Define('m_b1mu', m_b1mu)\\\n",
    "    .Define('dR_tt', dR_tt)\\\n",
    "    .Define('dR_b1ele', dR_b1ele)\\\n",
    "    .Define('dR_b1mu', dR_b1mu)\\\n",
    "    .Define('dR_b1tt', dR_b1tt)\\\n",
    "    .Define('tt_pt', tt_pt)\\\n",
    "    .Define('tt_eta', tt_eta)\\\n",
    "    .Define('mT_ele', mT_ele)\\\n",
    "    .Define('mT_mu', mT_mu)\\\n",
    "    .Define('mT_b1', mT_b1)\\\n",
    "    .Define('norm_zeta', norm_zeta)\\\n",
    "    .Define('x_zeta', x_zeta)\\\n",
    "    .Define('y_zeta', y_zeta)\\\n",
    "    .Define('p_zeta_mis', p_zeta_mis)\\\n",
    "    .Define('pzeta_vis', pzeta_vis)\\\n",
    "    .Define('Dzeta', Dzeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 2018\n",
    "for i in range(len(allfiles18)):\n",
    "    allfiles18[i] = pd.DataFrame(allfiles18[i].AsNumpy(feature_list))\n",
    "    allfiles18[i] = allfiles18[i].values\n",
    "    allfiles18[i] = scaler.transform(allfiles18[i])\n",
    "    print(inpaths18[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 2017\n",
    "for i in range(len(allfiles17)):\n",
    "    allfiles17[i] = pd.DataFrame(allfiles17[i].AsNumpy(feature_list))\n",
    "    allfiles17[i] = allfiles17[i].values\n",
    "    allfiles17[i] = scaler.transform(allfiles17[i])\n",
    "    print(inpaths17[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 2016\n",
    "for i in range(len(allfiles16)):\n",
    "    allfiles16[i] = pd.DataFrame(allfiles16[i].AsNumpy(feature_list))\n",
    "    allfiles16[i] = allfiles16[i].values\n",
    "    allfiles16[i] = scaler.transform(allfiles16[i])\n",
    "    print(inpaths16[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed to NN and write outputs to root files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 2018\n",
    "for i in range(len(allfiles18)):\n",
    "    y_pred = model.predict(allfiles18[i])\n",
    "    y_pred = np.array(y_pred, dtype = [('pred_1b', np.float32)])\n",
    "    array2root(y_pred, filename = outpaths18[i], treename = 'emu_tree_dnn', mode = 'update')\n",
    "    print(outpaths18[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######### 2017\n",
    "for i in range(len(allfiles17)):\n",
    "    y_pred = model.predict(allfiles17[i])\n",
    "    y_pred = np.array(y_pred, dtype = [('pred_1b', np.float32)])\n",
    "    array2root(y_pred, filename = outpaths17[i], treename = 'emu_tree_dnn', mode = 'update')\n",
    "    print(outpaths17[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 2016\n",
    "for i in range(len(allfiles16)):\n",
    "    y_pred = model.predict(allfiles16[i])\n",
    "    y_pred = np.array(y_pred, dtype = [('pred_1b', np.float32)])\n",
    "    array2root(y_pred, filename = outpaths16[i], treename = 'emu_tree_dnn', mode = 'update')\n",
    "    print(outpaths16[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
