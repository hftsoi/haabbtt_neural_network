{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for h->aa->bbtautau signal/background separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load root files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_obs = ROOT.RDataFrame('etau_tree', 'et16/data_obs.root')\n",
    "file_sig = ROOT.RDataFrame('etau_tree', {'et16/ggH_bbtt*.root', 'et16/vbf_bbtt*.root'})\n",
    "file_ZTT = ROOT.RDataFrame('etau_tree', 'et16/embedded.root')\n",
    "file_TT = ROOT.RDataFrame('etau_tree', 'et16/TT.root')\n",
    "\n",
    "files = [file_obs, file_sig, file_ZTT, file_TT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b events\n",
    "for i in range(len(files)):\n",
    "    files[i] = files[i].Filter('bpt_deepcsv_1>20 && bscore_deepcsv_1>0.6321 && bpt_deepcsv_2<0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b events\n",
    "for i in range(len(files)):\n",
    "    files[i] = files[i].Filter('bpt_deepcsv_1>20 && bscore_deepcsv_1>0.6321')\\\n",
    "    .Filter('bpt_deepcsv_2>20 && bscore_deepcsv_2>0.6321')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 4-vectors, invariant masses and etc.\n",
    "myele = 'ROOT::Math::PtEtaPhiMVector(pt_1,eta_1,phi_1,m_1)'\n",
    "mytau = 'ROOT::Math::PtEtaPhiMVector(pt_2,eta_2,phi_2,m_2)'\n",
    "mymet = 'ROOT::Math::PtEtaPhiMVector(met,0,metphi,0)'\n",
    "mytt = 'ROOT::Math::PtEtaPhiMVector((myele+mytau+mymet).Pt(),(myele+mytau+mymet).Eta(),(myele+mytau+mymet).Phi(),m_sv)'\n",
    "myb1 = 'ROOT::Math::PtEtaPhiMVector(bpt_deepcsv_1,beta_deepcsv_1,bphi_deepcsv_1,bm_deepcsv_1)'\n",
    "myb2 = 'ROOT::Math::PtEtaPhiMVector(bpt_deepcsv_2,beta_deepcsv_2,bphi_deepcsv_2,bm_deepcsv_2)'\n",
    "m_btt = '(mytt+myb1).M()'\n",
    "m_bbtt = '(mytt+myb1+myb2).M()'\n",
    "m_bb = '(myb1+myb2).M()'\n",
    "m_b1ele = '(myele+myb1).M()'\n",
    "m_b1tau = '(mytau+myb1).M()'\n",
    "m_b2ele = '(myele+myb2).M()'\n",
    "m_b2tau = '(mytau+myb2).M()'\n",
    "dR_tt = 'ROOT::Math::VectorUtil::DeltaR(myele,mytau)'\n",
    "dR_b1ele = 'ROOT::Math::VectorUtil::DeltaR(myele,myb1)'\n",
    "dR_b1tau = 'ROOT::Math::VectorUtil::DeltaR(mytau,myb1)'\n",
    "dR_b2ele = 'ROOT::Math::VectorUtil::DeltaR(myele,myb2)'\n",
    "dR_b2tau = 'ROOT::Math::VectorUtil::DeltaR(mytau,myb2)'\n",
    "dR_bb = 'ROOT::Math::VectorUtil::DeltaR(myb1,myb2)'\n",
    "tt_pt = 'mytt.Pt()'\n",
    "tt_eta = 'mytt.Eta()'\n",
    "bb_pt = '(myb1+myb2).Pt()'\n",
    "\n",
    "\n",
    "# define transverse masses mT and D_zeta\n",
    "mT_ele = 'sqrt(pow(myele.Pt()+mymet.Pt(),2)-pow(myele.Px()+mymet.Px(),2)-pow(myele.Py()+mymet.Py(),2))'\n",
    "mT_tau = 'sqrt(pow(mytau.Pt()+mymet.Pt(),2)-pow(mytau.Px()+mymet.Px(),2)-pow(mytau.Py()+mymet.Py(),2))'\n",
    "norm_zeta = 'sqrt(pow(myele.Px()/myele.Pt()+mytau.Px()/mytau.Pt(),2)+pow(myele.Py()/myele.Pt()+mytau.Py()/mytau.Pt(),2))'\n",
    "x_zeta = '(myele.Px()/myele.Pt()+mytau.Px()/mytau.Pt())/norm_zeta'\n",
    "y_zeta = '(myele.Py()/myele.Pt()+mytau.Py()/mytau.Pt())/norm_zeta'\n",
    "p_zeta_mis = 'mymet.Px()*x_zeta+mymet.Py()*y_zeta'\n",
    "pzeta_vis = '(myele.Px()+mytau.Px())*x_zeta+(myele.Py()+mytau.Py())*y_zeta'\n",
    "Dzeta = 'p_zeta_mis-0.85*pzeta_vis'\n",
    "\n",
    "\n",
    "# add defined variables to dataframe\n",
    "for i in range(len(files)):\n",
    "    files[i] = files[i].Define('myele', myele)\\\n",
    "    .Define('mytau', mytau)\\\n",
    "    .Define('mymet', mymet)\\\n",
    "    .Define('mytt', mytt)\\\n",
    "    .Define('myb1', myb1)\\\n",
    "    .Define('myb2', myb2)\\\n",
    "    .Define('m_btt', m_btt)\\\n",
    "    .Define('m_bbtt', m_bbtt)\\\n",
    "    .Define('m_bb', m_bb)\\\n",
    "    .Define('m_b1ele', m_b1ele)\\\n",
    "    .Define('m_b1tau', m_b1tau)\\\n",
    "    .Define('m_b2ele', m_b2ele)\\\n",
    "    .Define('m_b2tau', m_b2tau)\\\n",
    "    .Define('dR_tt', dR_tt)\\\n",
    "    .Define('dR_b1ele', dR_b1ele)\\\n",
    "    .Define('dR_b1tau', dR_b1tau)\\\n",
    "    .Define('dR_b2ele', dR_b2ele)\\\n",
    "    .Define('dR_b2tau', dR_b2tau)\\\n",
    "    .Define('dR_bb', dR_bb)\\\n",
    "    .Define('tt_pt', tt_pt)\\\n",
    "    .Define('tt_eta', tt_eta)\\\n",
    "    .Define('bb_pt', bb_pt)\\\n",
    "    .Define('mT_ele', mT_ele)\\\n",
    "    .Define('mT_tau', mT_tau)\\\n",
    "    .Define('norm_zeta', norm_zeta)\\\n",
    "    .Define('x_zeta', x_zeta)\\\n",
    "    .Define('y_zeta', y_zeta)\\\n",
    "    .Define('p_zeta_mis', p_zeta_mis)\\\n",
    "    .Define('pzeta_vis', pzeta_vis)\\\n",
    "    .Define('Dzeta', Dzeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply baseline selection cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016 e+tau trigger requirements\n",
    "trigger25 = '(passEle25 && matchEle25_1 && filterEle25_1 && pt_1>26)'\n",
    "\n",
    "for i in range(len(files)):\n",
    "    files[i] = files[i].Filter('Flag_goodVertices==0')\\\n",
    "    .Filter('Flag_globalSuperTightHalo2016Filter==0')\\\n",
    "    .Filter('Flag_HBHENoiseFilter==0')\\\n",
    "    .Filter('Flag_HBHENoiseIsoFilter==0')\\\n",
    "    .Filter('Flag_EcalDeadCellTriggerPrimitiveFilter==0')\\\n",
    "    .Filter('Flag_BadPFMuonFilter==0')\\\n",
    "    .Filter(trigger25)\\\n",
    "    .Filter('pt_2>20')\\\n",
    "    .Filter('fabs(eta_1)<2.1 && fabs(eta_2)<2.3')\\\n",
    "    .Filter('iso_1<0.15')\\\n",
    "    .Filter('byTightDeepVSe_2 && byVLooseDeepVSmu_2')\\\n",
    "    .Filter('dR_tt>0.4')\n",
    "\n",
    "files[0] = files[0].Filter('Flag_eeBadScFilter==0')\n",
    "files[2] = files[2].Filter('Flag_eeBadScFilter==0')\n",
    "\n",
    "files[3] = files[3].Filter('gen_match_2!=6').Filter('(gen_match_1==6 or gen_match_1<3) && (gen_match_2<3)')\n",
    "\n",
    "files[1] = files[1].Filter('gen_match_2!=6')\n",
    "\n",
    "files[2] = files[2].Filter('gen_match_2!=6').Filter('genweight<=1.0')\n",
    "\n",
    "# QCD region\n",
    "qcd = files[0].Filter('q_1*q_2>0').Filter('byMediumDeepVSjet_2==0')\n",
    "\n",
    "# signal region\n",
    "for i in range(len(files)):\n",
    "    files[i] = files[i].Filter('q_1*q_2<0')\\\n",
    "    .Filter('byMediumDeepVSjet_2')\n",
    "\n",
    "# [0]=obs, [1]=sig, [2]=embedded, [3]=ttbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select all input features and save into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13734, 16)\n",
      "(6815, 17)\n",
      "(24287, 17)\n",
      "(39, 17)\n",
      "(35816, 17)\n"
     ]
    }
   ],
   "source": [
    "# list of feature variables\n",
    "###### for 1b events\n",
    "feature_list = ['pt_1', 'pt_2', 'm_btt', 'm_b1ele', 'm_b1tau',\\\n",
    "                'dR_tt', 'dR_b1ele', 'dR_b1tau',\\\n",
    "                'tt_pt', 'tt_eta', 'mT_ele', 'mT_tau', 'Dzeta',\\\n",
    "                'bpt_deepcsv_1', 'met', 'njets']\n",
    "\n",
    "###### for 2b events\n",
    "#feature_list = ['pt_1', 'pt_2', 'm_btt', 'm_bbtt', 'm_bb', 'm_b1ele', 'm_b1tau', 'm_b2ele', 'm_b2tau',\\\n",
    "#                'dR_tt', 'dR_b1ele', 'dR_b1tau', 'dR_b2ele', 'dR_b2tau', 'dR_bb',\\\n",
    "#                'tt_pt', 'tt_eta', 'bb_pt', 'mT_ele', 'mT_tau', 'Dzeta',\\\n",
    "#                'bpt_deepcsv_1', 'bpt_deepcsv_2', 'met', 'njets']\n",
    "\n",
    "# convert root RDataFrame into pandas DataFrame, saving only the features as columns\n",
    "for i in range(len(files)):\n",
    "    files[i] = pd.DataFrame(files[i].AsNumpy(feature_list))\n",
    "qcd = pd.DataFrame(qcd.AsNumpy(feature_list))\n",
    "\n",
    "# tag MC signal events as class 1\n",
    "files[1]['label'] = np.ones((files[1].shape[0], 1))\n",
    "\n",
    "# tag MC background events as class 0\n",
    "files[2]['label'] = np.zeros((files[2].shape[0], 1))\n",
    "files[3]['label'] = np.zeros((files[3].shape[0], 1))\n",
    "qcd['label'] = np.zeros((qcd.shape[0],1))\n",
    "\n",
    "for i in range(len(files)):\n",
    "    print(str(files[i].shape))\n",
    "print(str(qcd.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into MC/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reduce class 0 sample size for balanced training\n",
    "files[2] = files[2].sample(n = 489, random_state = 20)\n",
    "files[3] = files[3].sample(n = 1000, random_state = 20)\n",
    "qcd = qcd.sample(n = 500, random_state = 20)\n",
    "\n",
    "\n",
    "# collect all MC as one dataframe, separated from another datafream for observed data\n",
    "df_obs = files[0]\n",
    "df_MC = [files[1], files[2], files[3], qcd]\n",
    "\n",
    "df_MC = pd.concat(df_MC)\n",
    "\n",
    "\n",
    "print('\\nObserved dataframe: \\n' + str(df_obs))\n",
    "print('\\nMC dataframe: \\n' + str(df_MC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare input feature distributions between sig and bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyplot.hist(files[1]['pt_1'], density = 1, range = (0,120), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['pt_1'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['pt_1'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['pt_1'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('e pt (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['pt_2'], density = 1, range = (0,120), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['pt_2'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['pt_2'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['pt_2'], density = 1, range = (0,120), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('$\\\\tau$ pt (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['m_btt'], density = 1, range = (30,450), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['m_btt'], density = 1, range = (30,450), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['m_btt'], density = 1, range = (30,450), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['m_btt'], density = 1, range = (30,450), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('m_b$\\\\tau\\\\tau$ (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['m_b1ele'], density = 1, range = (0,200), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['m_b1ele'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['m_b1ele'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['m_b1ele'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('m_b$_1$e (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['m_b1tau'], density = 1, range = (0,200), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['m_b1tau'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['m_b1tau'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['m_b1tau'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('m_b$_1$$\\\\tau_h$ (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['dR_tt'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['dR_tt'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['dR_tt'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['dR_tt'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('dR(e,$\\\\tau_h$)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['dR_b1ele'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['dR_b1ele'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['dR_b1ele'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['dR_b1ele'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('dR(b$_1$,e)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['dR_b1tau'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['dR_b1tau'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['dR_b1tau'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['dR_b1tau'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('dR(b$_1$,$\\\\tau_h$)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['tt_pt'], density = 1, range = (0,250), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['tt_pt'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['tt_pt'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['tt_pt'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('$\\\\tau\\\\tau$ pt (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['tt_eta'], density = 1, range = (-2.4,2.4), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['tt_eta'], density = 1, range = (-2.4,2.4), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['tt_eta'], density = 1, range = (-2.4,2.4), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['tt_eta'], density = 1, range = (-2.4,2.4), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('$\\\\tau\\\\tau$ $\\eta$')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['mT_ele'], density = 1, range = (0,150), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['mT_ele'], density = 1, range = (0,150), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['mT_ele'], density = 1, range = (0,150), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['mT_ele'], density = 1, range = (0,150), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('mT(e,met) (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['mT_tau'], density = 1, range = (0,150), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['mT_tau'], density = 1, range = (0,150), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['mT_tau'], density = 1, range = (0,150), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['mT_tau'], density = 1, range = (0,150), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('mT($\\\\tau_h$,met) (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['Dzeta'], density = 1, range = (-200,120), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['Dzeta'], density = 1, range = (-200,120), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['Dzeta'], density = 1, range = (-200,120), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['Dzeta'], density = 1, range = (-200,120), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('$D_\\zeta$ (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['bpt_deepcsv_1'], density = 1, range = (10,130), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['bpt_deepcsv_1'], density = 1, range = (10,130), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['bpt_deepcsv_1'], density = 1, range = (10,130), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['bpt_deepcsv_1'], density = 1, range = (10,130), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('Leading b jet pt (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['met'], density = 1, range = (0,200), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['met'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['met'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['met'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('MET (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['njets'], density = 1, range = (0,8), bins = 8, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['njets'], density = 1, range = (0,8), bins = 8, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['njets'], density = 1, range = (0,8), bins = 8, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['njets'], density = 1, range = (0,8), bins = 8, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('njets')\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "############## for 2b events\n",
    "pyplot.hist(files[1]['m_bbtt'], density = 1, range = (50,600), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['m_bbtt'], density = 1, range = (50,600), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['m_bbtt'], density = 1, range = (50,600), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['m_bbtt'], density = 1, range = (50,600), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('m_bb$\\\\tau\\\\tau$ (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['m_bb'], density = 1, range = (10,250), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['m_bb'], density = 1, range = (10,250), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['m_bb'], density = 1, range = (10,250), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['m_bb'], density = 1, range = (10,250), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('m_bb (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['m_b2ele'], density = 1, range = (0,200), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['m_b2ele'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['m_b2ele'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['m_b2ele'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('m_b$_2$ele (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['m_b2tau'], density = 1, range = (0,200), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['m_b2tau'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['m_b2tau'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['m_b2tau'], density = 1, range = (0,200), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('m_b$_2$$\\\\tau_h$ (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['dR_b2ele'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['dR_b2ele'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['dR_b2ele'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['dR_b2ele'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('dR(b$_2$,e)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['dR_b2tau'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['dR_b2tau'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['dR_b2tau'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['dR_b2tau'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('dR(b2,$\\\\tau_h$)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['dR_bb'], density = 1, range = (0,5), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['dR_bb'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['dR_bb'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['dR_bb'], density = 1, range = (0,5), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('dR(b1,b2)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['bb_pt'], density = 1, range = (0,250), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['bb_pt'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['bb_pt'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['bb_pt'], density = 1, range = (0,250), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('bb pt (GeV)')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.hist(files[1]['bpt_deepcsv_2'], density = 1, range = (10,130), bins = 50, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.hist(files[2]['bpt_deepcsv_2'], density = 1, range = (10,130), bins = 50, alpha = 1.0, label = 'ZTT', histtype = 'step')\n",
    "pyplot.hist(files[3]['bpt_deepcsv_2'], density = 1, range = (10,130), bins = 50, alpha = 1.0, label = 'ttbar', histtype = 'step')\n",
    "pyplot.hist(qcd['bpt_deepcsv_2'], density = 1, range = (10,130), bins = 50, alpha = 1.0, label = 'QCD', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper right')\n",
    "pyplot.xlabel('Sub-leading b jet pt (GeV)')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "dataset = df_MC.values\n",
    "X = dataset[:,0:(dataset.shape[1]-1)]\n",
    "Y = dataset[:,dataset.shape[1]-1]\n",
    "Y = Y.reshape(Y.shape[0],1)\n",
    "\n",
    "dataset_obs = df_obs.values\n",
    "X_obs = dataset_obs[:,0:(dataset_obs.shape[1])]\n",
    "\n",
    "#dataset_DY = df_DY.values\n",
    "#X_DY = dataset_DY[:,0:(dataset_DY.shape[1])]\n",
    "\n",
    "\n",
    "# give train/val/test partition ratios\n",
    "train_ratio = 0.9\n",
    "val_ratio = 0.05\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "\n",
    "# randomly partition data set into train/val/test sets with given ratios\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size = test_ratio, random_state=15)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = val_ratio/(val_ratio+train_ratio), random_state=15)\n",
    "\n",
    "# standardize feature variables\n",
    "# only based on means and stds in train_val set, should apply this only scaler to all other sets\n",
    "# think of the transformation in phase space\n",
    "scaler = StandardScaler().fit(X_train_val)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_obs = scaler.transform(X_obs)\n",
    "#X_DY = scaler.transform(X_DY)\n",
    "\n",
    "\n",
    "# print input data shapes\n",
    "print(\"\\nPartition the data set into train/val/test: %.2f/%.2f/%.2f\" % (train_ratio, val_ratio, test_ratio))\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"Y_train.shape: \" + str(Y_train.shape))\n",
    "print(\"X_val.shape: \" + str(X_val.shape))\n",
    "print(\"Y_val.shape: \" + str(Y_val.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))\n",
    "print(\"Y_test.shape: \" + str(Y_test.shape))\n",
    "print(\"\\nX_obs.shape: \" + str(X_obs.shape))\n",
    "\n",
    "# print ratio of signal/background examples in each set\n",
    "train_sig = np.count_nonzero(Y_train)\n",
    "train_bkg = np.count_nonzero(Y_train == 0)\n",
    "train_sig_perc = 100*train_sig/(train_sig+train_bkg)\n",
    "train_bkg_perc = 100*train_bkg/(train_sig+train_bkg)\n",
    "val_sig = np.count_nonzero(Y_val)\n",
    "val_bkg = np.count_nonzero(Y_val == 0)\n",
    "val_sig_perc = 100*val_sig/(val_sig+val_bkg)\n",
    "val_bkg_perc = 100*val_bkg/(val_sig+val_bkg)\n",
    "test_sig = np.count_nonzero(Y_test)\n",
    "test_bkg = np.count_nonzero(Y_test == 0)\n",
    "test_sig_perc = 100*test_sig/(test_sig+test_bkg)\n",
    "test_bkg_perc = 100*test_bkg/(test_sig+test_bkg)\n",
    "\n",
    "total_sig = train_sig + val_sig + test_sig\n",
    "total_bkg = train_bkg + val_bkg + test_bkg\n",
    "total_sig_perc = 100*total_sig/(total_sig+total_bkg)\n",
    "total_bkg_perc = 100*total_bkg/(total_sig+total_bkg)\n",
    "print(\"\\nTotal number of sig/bkg examples: %d/%d (%.2f%%/%.2f%%)\" % (total_sig, total_bkg, total_sig_perc, total_bkg_perc))\n",
    "\n",
    "print(\"\\nNumber of sig/bkg examples in each set:\")\n",
    "print(\"train : %d/%d (%.1f%%/%.1f%%)\" % (train_sig, train_bkg, train_sig_perc, train_bkg_perc))\n",
    "print(\"val   : %d/%d (%.1f%%/%.1f%%)\" % (val_sig, val_bkg, val_sig_perc, val_bkg_perc))\n",
    "print(\"test  : %d/%d (%.1f%%/%.1f%%)\" % (test_sig, test_bkg, test_sig_perc, test_bkg_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network achitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## input layer ########\n",
    "X_input = Input(shape = (X.shape[1],), name = 'X_input')\n",
    "\n",
    "\n",
    "######## hidden layers ########\n",
    "hidden_1 = Dense(\n",
    "    units = 20,\n",
    "    activation = 'relu',\n",
    "    kernel_initializer = glorot_uniform(seed=1),\n",
    "    name = 'Hidden_layer_1'\n",
    ")(X_input)\n",
    "\n",
    "hidden_2 = Dense(\n",
    "    units = 20,\n",
    "    activation = 'relu',\n",
    "    kernel_initializer = glorot_uniform(seed=1),\n",
    "    name = 'Hidden_layer_2'\n",
    ")(hidden_1)\n",
    "\n",
    "\n",
    "######## output layer #######\n",
    "Y_output = Dense(\n",
    "    units = 1,\n",
    "    activation = 'sigmoid',\n",
    "    kernel_initializer = glorot_uniform(seed=1),\n",
    "    name = 'Y_output'\n",
    ")(hidden_2)\n",
    "\n",
    "\n",
    "model = Model(inputs = X_input, outputs = Y_output)\n",
    "\n",
    "# use adaptive moment estimation (adam) to train, which uses both GD with momentum and RMSprop\n",
    "# the default hyperparameters in adam are usually good enough\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) ### accuracy = freq. of y_pred = y_true\n",
    "\n",
    "# show model details\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1 epoch = 1 pass through the data set\n",
    "# typical mini-batch size = 2^n for faster computation\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs = 80,\n",
    "                    validation_data = (X_val, Y_val),\n",
    "                    batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/validation performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss vs epoch\n",
    "plt.figure(figsize = (15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label = 'train loss')\n",
    "axes.plot(history.history['val_loss'], label = 'val loss')\n",
    "axes.legend(loc = \"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')\n",
    "\n",
    "# plot accuracy vs epoch\n",
    "axes = plt.subplot(2, 2, 2)\n",
    "axes.plot(history.history['accuracy'], label = 'train accuracy')\n",
    "axes.plot(history.history['val_accuracy'], label = 'val accuracy')\n",
    "axes.legend(loc = \"lower right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Accuracy (y_pred = y_true)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the test set into sig/bkg sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count sig/bkg examples in the test set\n",
    "test_sig_number = np.count_nonzero(Y_test)\n",
    "test_bkg_number = np.count_nonzero(Y_test == 0)\n",
    "\n",
    "X_test_sig = np.zeros((test_sig_number,X_test.shape[1]))\n",
    "X_test_bkg = np.zeros((test_bkg_number,X_test.shape[1]))\n",
    "\n",
    "j = 0\n",
    "k = 0\n",
    "for i in range(Y_test.shape[0]):\n",
    "    if Y_test[i,0] == 1:\n",
    "        X_test_sig[j,:] = X_test[i,:]\n",
    "        j = j + 1\n",
    "    else:\n",
    "        X_test_bkg[k,:] = X_test[i,:]\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyplot.hist(model.predict(X_test_bkg), density = 1, range = (0.0, 1.0), bins = 10, alpha = 0.3, label = 'ZTT, ttbar, QCD')\n",
    "pyplot.hist(model.predict(X_test_sig), density = 1, range = (0.0, 1.0), bins = 10, alpha = 0.3, label = 'h->aa->bbtautau')\n",
    "pyplot.legend(loc = 'upper center')\n",
    "pyplot.title('Model prediction on test set (unbias), normalized')\n",
    "pyplot.xlabel('Predicted probability of being a signal event')\n",
    "pyplot.xticks(np.arange(0, 1.1, step = 0.1))\n",
    "pyplot.show()\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure(figsize = (13,13))\n",
    "Y_predict = model.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_predict)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(fpr, tpr, lw = 2, color = 'red', label = 'ROC curve for test set, AUC (area) = %.3f' % (roc_auc))\n",
    "axes.plot([0, 1], [0, 1], linestyle = '--', lw = 2, color = 'black', label = 'random chance')\n",
    "axes.set_xlim([0, 1.0])\n",
    "axes.set_ylim([0, 1.0])\n",
    "axes.set_xlabel('False positive rate (FPR)')\n",
    "axes.set_ylabel('True positive rate (TPR)')\n",
    "axes.set_title('Receiver operating characteristic (ROC)')\n",
    "axes.legend(loc = \"lower right\")\n",
    "plt.show()\n",
    "\n",
    "results = model.evaluate(X_test, Y_test, verbose = 0, batch_size = 256)\n",
    "print(\"Test loss, test accuracy:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on the observed data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.hist(model.predict(X_obs), density = 1, range = (0.0, 1.0), bins = 10, alpha = 0.3, label = 'Observed data')\n",
    "#pyplot.hist(model.predict(X_test_bkg), density = 1, range = (0.0, 1.0), bins = 10, alpha = 1.0, label = 'ZTT, ttbar, QCD (MC test set)', histtype = 'step')\n",
    "#pyplot.hist(model.predict(X_test_sig), density = 1, range = (0.0, 1.0), bins = 10, alpha = 1.0, label = 'h->aa->bbtautau (MC test set)', histtype = 'step')\n",
    "pyplot.legend(loc = 'upper center')\n",
    "pyplot.title('Model prediction on observed data set, normalized')\n",
    "pyplot.xlabel('Predicted probability of being a signal event')\n",
    "pyplot.xticks(np.arange(0, 1.1, step = 0.1))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write model prediction to root files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all root files one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from root_numpy import array2root\n",
    "\n",
    "paths = ['et16/DY.root', 'et16/DY1.root', 'et16/DY2.root', 'et16/DY3.root', 'et16/DY4.root'\\\n",
    "         , 'et16/GGHTT.root', 'et16/GGHWW.root', 'et16/GGZHLLTT.root', 'et16/GGZHNNTT.root'\\\n",
    "         , 'et16/GGZHQQTT.root', 'et16/GGZHWW.root', 'et16/ST_tW_antitop.root'\\\n",
    "         , 'et16/ST_tW_top.root', 'et16/ST_t_antitop.root', 'et16/ST_t_top.root'\\\n",
    "         , 'et16/TT.root', 'et16/VBFHTT.root', 'et16/VBFHWW.root', 'et16/VV2L2Nu.root'\\\n",
    "         , 'et16/WZ2L2Q.root', 'et16/WZ3L1Nu.root', 'et16/WminusHTT.root', 'et16/WminusHWW.root'\\\n",
    "         , 'et16/WplusHTT.root', 'et16/WplusHWW.root', 'et16/ZHTT.root', 'et16/ZHWW.root'\\\n",
    "         , 'et16/ZZ2L2Q.root', 'et16/ZZ4L.root', 'et16/data_obs.root', 'et16/embedded.root'\\\n",
    "         , 'et16/ggH_bbtt15.root', 'et16/ggH_bbtt20.root', 'et16/ggH_bbtt25.root'\\\n",
    "         , 'et16/ggH_bbtt30.root', 'et16/ggH_bbtt35.root', 'et16/ggH_bbtt40.root'\\\n",
    "         , 'et16/ggH_bbtt45.root', 'et16/ggH_bbtt50.root', 'et16/ggH_bbtt55.root'\\\n",
    "         , 'et16/ggH_bbtt60.root', 'et16/ttHnonbb.root', 'et16/vbf_bbtt15.root'\\\n",
    "         , 'et16/vbf_bbtt20.root', 'et16/vbf_bbtt25.root', 'et16/vbf_bbtt30.root'\\\n",
    "         , 'et16/vbf_bbtt35.root', 'et16/vbf_bbtt40.root', 'et16/vbf_bbtt45.root'\\\n",
    "         , 'et16/vbf_bbtt50.root', 'et16/vbf_bbtt55.root', 'et16/vbf_bbtt60.root']\n",
    "\n",
    "allfiles = []\n",
    "for i in range(len(paths)):\n",
    "    allfiles.append(ROOT.RDataFrame('etau_tree', paths[i]))\n",
    "\n",
    "\n",
    "for i in range(len(allfiles)):\n",
    "    allfiles[i] = allfiles[i].Define('myele', myele)\\\n",
    "    .Define('mytau', mytau)\\\n",
    "    .Define('mymet', mymet)\\\n",
    "    .Define('mytt', mytt)\\\n",
    "    .Define('myb1', myb1)\\\n",
    "    .Define('myb2', myb2)\\\n",
    "    .Define('m_btt', m_btt)\\\n",
    "    .Define('m_bbtt', m_bbtt)\\\n",
    "    .Define('m_bb', m_bb)\\\n",
    "    .Define('m_b1ele', m_b1ele)\\\n",
    "    .Define('m_b1tau', m_b1tau)\\\n",
    "    .Define('m_b2ele', m_b2ele)\\\n",
    "    .Define('m_b2tau', m_b2tau)\\\n",
    "    .Define('dR_tt', dR_tt)\\\n",
    "    .Define('dR_b1ele', dR_b1ele)\\\n",
    "    .Define('dR_b1tau', dR_b1tau)\\\n",
    "    .Define('dR_b2ele', dR_b2ele)\\\n",
    "    .Define('dR_b2tau', dR_b2tau)\\\n",
    "    .Define('dR_bb', dR_bb)\\\n",
    "    .Define('tt_pt', tt_pt)\\\n",
    "    .Define('tt_eta', tt_eta)\\\n",
    "    .Define('bb_pt', bb_pt)\\\n",
    "    .Define('mT_ele', mT_ele)\\\n",
    "    .Define('mT_tau', mT_tau)\\\n",
    "    .Define('norm_zeta', norm_zeta)\\\n",
    "    .Define('x_zeta', x_zeta)\\\n",
    "    .Define('y_zeta', y_zeta)\\\n",
    "    .Define('p_zeta_mis', p_zeta_mis)\\\n",
    "    .Define('pzeta_vis', pzeta_vis)\\\n",
    "    .Define('Dzeta', Dzeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(allfiles)):\n",
    "    allfiles[i] = pd.DataFrame(allfiles[i].AsNumpy(feature_list))\n",
    "    allfiles[i] = allfiles[i].values\n",
    "    allfiles[i] = scaler.transform(allfiles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed to NN and write outputs to root files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(allfiles)):\n",
    "    y_pred = model.predict(allfiles[i])\n",
    "    y_pred = np.array(y_pred, dtype = [('pred_2b', np.float32)])\n",
    "    array2root(y_pred, filename = paths[i], treename = 'etau_tree', mode = 'update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
